import logging
from pathlib import Path
from typing import List, Dict, Optional

import pdfplumber
from tqdm import tqdm

from local_config import (
    ENABLE_OCR,
    ENABLE_TABLES,
    OCR_LANGUAGES,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
    ENABLE_TEXT_CLEANING,
    ENABLE_DOCLING,
    MAX_DOCLING_PAGES,
)

from local_ollama_client import OllamaClient

logger = logging.getLogger(__name__)

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å PaddleOCR
try:
    from paddleocr import PaddleOCR
    PADDLEOCR_AVAILABLE = True
except ImportError:
    PADDLEOCR_AVAILABLE = False
    logging.warning("‚ö†Ô∏è PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, OCR –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω.")

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å Docling
try:
    from docling.document_converter import DocumentConverter
    DOCLING_AVAILABLE = True
except ImportError:
    DOCLING_AVAILABLE = False
    logging.warning("‚ö†Ô∏è Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª Docling –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω.")


class TextCleaner:
    """–ß–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM (Ollama)"""

    def __init__(self):
        self.enabled = ENABLE_TEXT_CLEANING
        self.ollama = OllamaClient()

    def clean_text(self, text: str, file_name: str = "", page: int = 0) -> str:
        if not self.enabled or not text.strip():
            return text

        system_prompt = (
            "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.\n\n"
            "–ó–ê–î–ê–ß–ê:\n"
            "- –£–¥–∞–ª–∏ –ø–æ–≤—Ç–æ—Ä—ã —Å—Ç—Ä–æ–∫, –º—É—Å–æ—Ä, –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.\n"
            "- –°–æ—Ö—Ä–∞–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è, –ì–û–°–¢—ã, –Ω–æ–º–µ—Ä–∞ —Å—Ö–µ–º –∏ —Ç.–ø.\n"
            "- –ù–µ —Å–æ–∫—Ä–∞—â–∞–π —Å–º—ã—Å–ª, –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Å–∏–ª—å–Ω–æ.\n"
            "- –ü—Ä–æ—Å—Ç–æ —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."
        )

        user_prompt = f"–§–∞–π–ª: {file_name}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page}\n\n–¢–µ–∫—Å—Ç:\n{text}"

        try:
            cleaned = self.ollama.generate(
                prompt=user_prompt,
                system_prompt=system_prompt,
                temperature=0.1,
                max_tokens=512,
            )
            return cleaned.strip()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM: {repr(e)}")
            return text


class DocumentProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: PDF, DOCX, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, OCR, Docling, —á–∞–Ω–∫–∏"""

    def __init__(self):
        self.text_cleaner = TextCleaner()

        # OCR
        if ENABLE_OCR and PADDLEOCR_AVAILABLE:
            try:
                self.ocr = PaddleOCR(
                    use_angle_cls=True,
                    lang='ru',
                    use_gpu=False,
                    show_log=False,
                )
                logger.info("‚úÖ PaddleOCR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PaddleOCR: {repr(e)}")
                self.ocr = None
        else:
            self.ocr = None
            if ENABLE_OCR and not PADDLEOCR_AVAILABLE:
                logger.warning("‚ö†Ô∏è ENABLE_OCR=true, –Ω–æ PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        # Docling
        self.use_docling = ENABLE_DOCLING and DOCLING_AVAILABLE
        if self.use_docling:
            try:
                self.docling_converter = DocumentConverter()
                logger.info("‚úÖ Docling –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Docling: {repr(e)}")
                self.use_docling = False
                self.docling_converter = None
        else:
            if ENABLE_DOCLING and not DOCLING_AVAILABLE:
                logger.warning("‚ö†Ô∏è ENABLE_DOCLING=true, –Ω–æ Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (pip install docling)")
            self.docling_converter = None

        logger.info("‚úÖ DocumentProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (OCR=%s, Docling=%s)", bool(self.ocr), self.use_docling)

    def process_file(self, file_path: Path) -> List[Dict]:
        ext = file_path.suffix.lower()

        if ext == ".pdf":
            return self._process_pdf(file_path)
        elif ext == ".docx":
            return self._process_docx(file_path)
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_path.name}")
            return []

    def _process_pdf(self, file_path: Path) -> List[Dict]:
        """–ì–∏–±—Ä–∏–¥–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF (+ Docling, + OCR)"""
        fragments = []

        # Docling –ø–æ –≤—Å–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É (—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ)
        docling_page_texts: Optional[Dict[int, str]] = None
        if self.use_docling:
            docling_page_texts = self._extract_with_docling(file_path)

        try:
            with pdfplumber.open(file_path) as pdf:
                num_pages = len(pdf.pages)
                logger.info(f"üìÑ PDF: {file_path.name}, —Å—Ç—Ä–∞–Ω–∏—Ü: {num_pages}")

                for page_num, page in enumerate(pdf.pages, start=1):
                    logger.debug(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}/{num_pages}...")

                    # 1. –¢–µ–∫—Å—Ç —á–µ—Ä–µ–∑ pdfplumber
                    text = page.extract_text() or ""
                    text = text.strip()

                    # 2. –¢–∞–±–ª–∏—Ü—ã
                    tables_text = ""
                    if ENABLE_TABLES:
                        tables = page.extract_tables()
                        if tables:
                            tables_text = self._format_tables(tables)
                            logger.debug(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)}")

                    # 3. OCR, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ
                    ocr_text = ""
                    if self.ocr and len(text) < 300:
                        logger.debug(f"      üîç –ú–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ({len(text)} —Å–∏–º–≤.), –∑–∞–ø—É—Å–∫–∞—é OCR...")
                        ocr_text = self._ocr_page_image(page)

                    # 4. Docling —Ç–µ–∫—Å—Ç –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    docling_text = ""
                    if docling_page_texts and page_num in docling_page_texts:
                        docling_text = docling_page_texts[page_num]
                        logger.debug(f"      üìë Docling: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(docling_text)} —Å–∏–º–≤–æ–ª–æ–≤")

                    # 5. –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å—ë
                    combined_text = "\n\n".join(
                        part for part in [text, tables_text, ocr_text, docling_text] if part and part.strip()
                    ).strip()

                    if not combined_text:
                        logger.debug(f"      ‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –ø—É—Å—Ç–∞—è, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                        continue

                    # 6. –ß–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ LLM
                    cleaned_text = self.text_cleaner.clean_text(
                        combined_text,
                        file_name=file_path.name,
                        page=page_num,
                    )

                    # 7. –ß–∞–Ω–∫–∏
                    chunks = self._split_into_chunks(cleaned_text)

                    for chunk in chunks:
                        fragments.append({
                            "content": chunk,
                            "page": page_num,
                            "type": "text",
                            "file": file_path.name,
                        })

                logger.info(f"‚úÖ PDF {file_path.name}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(fragments)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                return fragments

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF {file_path.name}: {repr(e)}")
            return []

    def _extract_with_docling(self, file_path: Path) -> Optional[Dict[int, str]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é Docling –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: {page_num: text}
        """
        if not self.use_docling or not self.docling_converter:
            return None

        try:
            logger.info(f"üìë Docling: –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–∞–π–ª–∞ {file_path.name}")
            result = self.docling_converter.convert(str(file_path))

            page_texts: Dict[int, str] = {}

            for page in result.document.pages:
                page_num = page.page_number or 0
                if page_num == 0:
                    continue

                if page_num > MAX_DOCLING_PAGES:
                    continue

                lines = []
                for block in page.blocks:
                    txt = block.to_text().strip()
                    if txt:
                        lines.append(txt)

                if lines:
                    page_texts[page_num] = "\n".join(lines)

            logger.info(f"üìë Docling: –ø–æ–ª—É—á–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Å —Ç–µ–∫—Å—Ç–æ–º: {len(page_texts)}")
            return page_texts if page_texts else None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Docling –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path.name}: {repr(e)}")
            return None

    def _ocr_page_image(self, page) -> str:
        """OCR —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ PaddleOCR (–∏–∑ pdfplumber page)"""
        if not self.ocr:
            logger.debug("    ‚ö†Ô∏è OCR –≤—ã–∫–ª—é—á–µ–Ω (self.ocr is None)")
            return ""

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            logger.debug("    üñº –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            img = page.to_image(resolution=150).original

            logger.debug("    üî† –ó–∞–ø—É—Å–∫ PaddleOCR...")
            result = self.ocr.ocr(img, cls=True)

            if not result or not result[0]:
                logger.debug("    ‚ö†Ô∏è OCR –Ω–µ –Ω–∞—à—ë–ª —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                return ""

            lines = []
            for line in result[0]:
                text = line[1][0] if len(line) > 1 else ""
                if text:
                    lines.append(text)

            ocr_text = "\n".join(lines)
            logger.debug(f"    ‚úÖ OCR –∏–∑–≤–ª—ë–∫ {len(ocr_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return ocr_text

        except AssertionError as e:
            logger.error(f"‚ùå AssertionError –≤ OCR: {repr(e)}")
            return ""
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OCR: {repr(e)}")
            return ""

    def _format_tables(self, tables) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ —Ç–µ–∫—Å—Ç"""
        parts = []
        for t in tables:
            for row in t:
                row = [str(cell).strip() if cell else "" for cell in row]
                parts.append(" | ".join(row))
            parts.append("\n")
        return "\n".join(parts)

    def _process_docx(self, file_path: Path) -> List[Dict]:
        """–ü—Ä–æ—Å—Ç–µ–π—à–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DOCX"""
        try:
            from docx import Document
        except ImportError:
            logger.error("‚ùå –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX –Ω—É–∂–µ–Ω –ø–∞–∫–µ—Ç python-docx (pip install python-docx)")
            return []

        fragments = []
        try:
            doc = Document(str(file_path))
            full_text = []

            for para in doc.paragraphs:
                txt = (para.text or "").strip()
                if txt:
                    full_text.append(txt)

            combined = "\n".join(full_text).strip()
            if not combined:
                return []

            cleaned_text = self.text_cleaner.clean_text(
                combined,
                file_name=file_path.name,
                page=1,
            )

            chunks = self._split_into_chunks(cleaned_text)
            for chunk in chunks:
                fragments.append({
                    "content": chunk,
                    "page": 1,
                    "type": "text",
                    "file": file_path.name,
                })

            logger.info(f"‚úÖ DOCX {file_path.name}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(fragments)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            return fragments

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOCX {file_path.name}: {repr(e)}")
            return []

    def _split_into_chunks(self, text: str) -> List[str]:
        """–†–µ–∂–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏"""
        if not text:
            return []

        chunks = []
        start = 0
        length = len(text)

        while start < length:
            end = min(start + CHUNK_SIZE, length)
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            start += CHUNK_SIZE - CHUNK_OVERLAP

        return chunks
#km