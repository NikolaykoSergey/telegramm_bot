import logging
import re
from pathlib import Path
from typing import List, Dict, Optional

import pdfplumber
from tqdm import tqdm

from local_config import (
    ENABLE_OCR,
    ENABLE_TABLES,
    OCR_LANGUAGES,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
    ENABLE_TEXT_CLEANING,
    ENABLE_DOCLING,
    MAX_DOCLING_PAGES,
)

from local_ollama_client import OllamaClient

logger = logging.getLogger(__name__)

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å PaddleOCR
try:
    from paddleocr import PaddleOCR
    PADDLEOCR_AVAILABLE = True
except ImportError:
    PADDLEOCR_AVAILABLE = False
    logging.warning("‚ö†Ô∏è PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, OCR –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω.")

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å Docling
try:
    from docling.document_converter import DocumentConverter
    DOCLING_AVAILABLE = True
except ImportError:
    DOCLING_AVAILABLE = False
    logging.warning("‚ö†Ô∏è Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª Docling –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω.")


def is_trash_text(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞, –≥–æ–¥–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî –º—É—Å–æ—Ä (—Å–ª–∏—à–∫–æ–º –º–∞–ª–æ, –±–∏—Ç–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã).
    """
    if not text:
        return True

    cleaned = text.strip()
    if len(cleaned) < 200:  # –º–µ–Ω–µ–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ ‚Äî –º–∞–ª–æ –¥–ª—è –º–∞–Ω—É–∞–ª–∞
        return True

    # –î–æ–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –±—É–∫–≤ vs –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ
    letters = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë]", cleaned)
    ratio = len(letters) / max(len(cleaned), 1)
    if ratio < 0.3:
        # –º–µ–Ω—å—à–µ 30% –±—É–∫–≤ ‚Äî –ø–æ—Ö–æ–∂–µ –Ω–∞ –º—É—Å–æ—Ä
        return True

    return False


class TextCleaner:
    """–ß–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM (Ollama)"""

    def __init__(self):
        self.enabled = ENABLE_TEXT_CLEANING
        self.ollama = OllamaClient()

    def clean_text(self, text: str, file_name: str = "", page: int = 0) -> str:
        if not self.enabled or not text.strip():
            return text

        system_prompt = (
            "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.\n\n"
            "–ó–ê–î–ê–ß–ê:\n"
            "- –£–¥–∞–ª–∏ –ø–æ–≤—Ç–æ—Ä—ã —Å—Ç—Ä–æ–∫, –º—É—Å–æ—Ä, –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.\n"
            "- –°–æ—Ö—Ä–∞–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è, –ì–û–°–¢—ã, –Ω–æ–º–µ—Ä–∞ —Å—Ö–µ–º –∏ —Ç.–ø.\n"
            "- –ù–µ —Å–æ–∫—Ä–∞—â–∞–π —Å–º—ã—Å–ª, –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Å–∏–ª—å–Ω–æ.\n"
            "- –ü—Ä–æ—Å—Ç–æ —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."
        )

        user_prompt = f"–§–∞–π–ª: {file_name}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page}\n\n–¢–µ–∫—Å—Ç:\n{text}"

        try:
            cleaned = self.ollama.generate(
                prompt=user_prompt,
                system_prompt=system_prompt,
                temperature=0.1,
                max_tokens=512,
            )
            return cleaned.strip()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM: {repr(e)}")
            return text


class DocumentProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: PDF, DOCX, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, OCR, Docling, —á–∞–Ω–∫–∏"""

    def __init__(self):
        self.text_cleaner = TextCleaner()

        # OCR
        if ENABLE_OCR and PADDLEOCR_AVAILABLE:
            try:
                self.ocr = PaddleOCR(
                    use_angle_cls=True,
                    lang='ru',
                    use_gpu=False,
                    show_log=False,
                )
                logger.info("‚úÖ PaddleOCR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PaddleOCR: {repr(e)}")
                self.ocr = None
        else:
            self.ocr = None
            if ENABLE_OCR and not PADDLEOCR_AVAILABLE:
                logger.warning("‚ö†Ô∏è ENABLE_OCR=true, –Ω–æ PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        # Docling
        self.use_docling = ENABLE_DOCLING and DOCLING_AVAILABLE
        if self.use_docling:
            try:
                self.docling_converter = DocumentConverter()
                logger.info("‚úÖ Docling –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Docling: {repr(e)}")
                self.use_docling = False
                self.docling_converter = None
        else:
            if ENABLE_DOCLING and not DOCLING_AVAILABLE:
                logger.warning("‚ö†Ô∏è ENABLE_DOCLING=true, –Ω–æ Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (pip install docling)")
            self.docling_converter = None

        logger.info("‚úÖ DocumentProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (OCR=%s, Docling=%s)", bool(self.ocr), self.use_docling)

    def process_file(self, file_path: Path) -> List[Dict]:
        ext = file_path.suffix.lower()

        if ext == ".pdf":
            return self._process_pdf(file_path)
        elif ext == ".docx":
            return self._process_docx(file_path)
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_path.name}")
            return []

    def _process_pdf(self, file_path: Path) -> List[Dict]:
        """
        –†–æ–±–∞—Å—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF –ø–æ —Å—Ö–µ–º–µ:
        1) pdfplumber (—Ç–µ–∫—Å—Ç + —Ç–∞–±–ª–∏—Ü—ã)
        2) –µ—Å–ª–∏ –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ‚Üí docling
        3) –µ—Å–ª–∏ –∏ docling –Ω–µ –¥–∞–ª ‚Üí OCR –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º —Å—Ç—Ä–∞–Ω–∏—Ü
        4) —á–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ LLM
        5) —á–∞–Ω–∫–∏ ‚Üí –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        """
        fragments = []

        try:
            with pdfplumber.open(file_path) as pdf:
                num_pages = len(pdf.pages)
                logger.info(f"üìÑ PDF: {file_path.name}, —Å—Ç—Ä–∞–Ω–∏—Ü: {num_pages}")

                for page_num, page in enumerate(pdf.pages, start=1):
                    logger.debug(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}/{num_pages}...")

                    # 1. –ë–ê–ó–û–í–´–ô –¢–ï–ö–°–¢ (pdfplumber)
                    text = page.extract_text() or ""
                    text = text.strip()

                    # 2. –¢–ê–ë–õ–ò–¶–´
                    tables_text = ""
                    if ENABLE_TABLES:
                        tables = page.extract_tables()
                        if tables:
                            tables_text = self._format_tables(tables)
                            logger.debug(f"      ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)}")

                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç + —Ç–∞–±–ª–∏—Ü—ã
                    combined_text = "\n\n".join(part for part in [text, tables_text] if part and part.strip()).strip()

                    # 3. –ü–†–û–í–ï–†–ö–ê: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ –∏–ª–∏ –º—É—Å–æ—Ä ‚Üí –ø—Ä–æ–±—É–µ–º docling
                    if is_trash_text(combined_text):
                        logger.debug(f"      ‚ö†Ô∏è –ú–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ({len(combined_text)} —Å–∏–º–≤.), –ø—Ä–æ–±—É–µ–º docling...")

                        docling_text = self._extract_page_with_docling(file_path, page_num)
                        if docling_text and not is_trash_text(docling_text):
                            logger.debug(f"      ‚úÖ Docling –¥–∞–ª {len(docling_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                            combined_text = docling_text
                        else:
                            logger.debug(f"      ‚ö†Ô∏è Docling —Ç–æ–∂–µ –Ω–µ –ø–æ–º–æ–≥, –∏–¥—ë–º –≤ OCR...")

                            # 4. OCR –ü–û –ö–ê–†–¢–ò–ù–ö–ï –°–¢–†–ê–ù–ò–¶–´
                            if self.ocr:
                                ocr_text = self._ocr_page_image(page)
                                if ocr_text and not is_trash_text(ocr_text):
                                    logger.debug(f"      ‚úÖ OCR –¥–∞–ª {len(ocr_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                                    combined_text = ocr_text
                                else:
                                    logger.debug(f"      ‚ùå OCR —Ç–æ–∂–µ –Ω–µ –¥–∞–ª –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")

                    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    if not combined_text or is_trash_text(combined_text):
                        logger.debug(f"      ‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –ø—É—Å—Ç–∞—è –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                        continue

                    # 5. –ß–ò–°–¢–ö–ê –ß–ï–†–ï–ó LLM
                    cleaned_text = self.text_cleaner.clean_text(
                        combined_text,
                        file_name=file_path.name,
                        page=page_num,
                    )

                    # 6. –ß–ê–ù–ö–ò
                    chunks = self._split_into_chunks(cleaned_text)

                    for chunk in chunks:
                        fragments.append({
                            "content": chunk,
                            "page": page_num,
                            "type": "text",
                            "file": file_path.name,
                        })

                logger.info(f"‚úÖ PDF {file_path.name}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(fragments)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                return fragments

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF {file_path.name}: {repr(e)}")
            return []

    def _extract_page_with_docling(self, file_path: Path, page_num: int) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ Docling.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
        """
        if not self.use_docling or not self.docling_converter:
            return ""

        if page_num > MAX_DOCLING_PAGES:
            return ""

        try:
            result = self.docling_converter.convert(str(file_path))

            for page in result.document.pages:
                if page.page_number == page_num:
                    lines = []
                    for block in page.blocks:
                        txt = block.to_text().strip()
                        if txt:
                            lines.append(txt)

                    if lines:
                        return "\n".join(lines)

            return ""

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Docling –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num} —Ñ–∞–π–ª–∞ {file_path.name}: {repr(e)}")
            return ""

    def _ocr_page_image(self, page) -> str:
        """OCR —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ PaddleOCR (–∏–∑ pdfplumber page)"""
        if not self.ocr:
            return ""

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            logger.debug("    üñº –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            img = page.to_image(resolution=150).original

            logger.debug("    üî† –ó–∞–ø—É—Å–∫ PaddleOCR...")
            result = self.ocr.ocr(img, cls=True)

            if not result or not result[0]:
                logger.debug("    ‚ö†Ô∏è OCR –Ω–µ –Ω–∞—à—ë–ª —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                return ""

            lines = []
            for line in result[0]:
                text = line[1][0] if len(line) > 1 else ""
                if text:
                    lines.append(text)

            ocr_text = "\n".join(lines)
            logger.debug(f"    ‚úÖ OCR –∏–∑–≤–ª—ë–∫ {len(ocr_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return ocr_text

        except AssertionError as e:
            logger.error(f"‚ùå AssertionError –≤ OCR: {repr(e)}")
            return ""
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ OCR: {repr(e)}")
            return ""

    def _format_tables(self, tables) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ —Ç–µ–∫—Å—Ç"""
        parts = []
        for t in tables:
            for row in t:
                row = [str(cell).strip() if cell else "" for cell in row]
                parts.append(" | ".join(row))
            parts.append("\n")
        return "\n".join(parts)

    def _process_docx(self, file_path: Path) -> List[Dict]:
        """–ü—Ä–æ—Å—Ç–µ–π—à–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DOCX"""
        try:
            from docx import Document
        except ImportError:
            logger.error("‚ùå –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX –Ω—É–∂–µ–Ω –ø–∞–∫–µ—Ç python-docx (pip install python-docx)")
            return []

        fragments = []
        try:
            doc = Document(str(file_path))
            full_text = []

            for para in doc.paragraphs:
                txt = (para.text or "").strip()
                if txt:
                    full_text.append(txt)

            combined = "\n".join(full_text).strip()
            if not combined:
                return []

            cleaned_text = self.text_cleaner.clean_text(
                combined,
                file_name=file_path.name,
                page=1,
            )

            chunks = self._split_into_chunks(cleaned_text)
            for chunk in chunks:
                fragments.append({
                    "content": chunk,
                    "page": 1,
                    "type": "text",
                    "file": file_path.name,
                })

            logger.info(f"‚úÖ DOCX {file_path.name}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(fragments)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            return fragments

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOCX {file_path.name}: {repr(e)}")
            return []

    def _split_into_chunks(self, text: str) -> List[str]:
        """–†–µ–∂–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏"""
        if not text:
            return []

        chunks = []
        start = 0
        length = len(text)

        while start < length:
            end = min(start + CHUNK_SIZE, length)
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            start += CHUNK_SIZE - CHUNK_OVERLAP

        return chunks