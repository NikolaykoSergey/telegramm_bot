import logging
import re
import time
import psutil
from pathlib import Path
from typing import List, Dict, Optional

import pdfplumber
from tqdm import tqdm

from local_config import (
    ENABLE_OCR,
    ENABLE_TABLES,
    OCR_LANGUAGES,
    CHUNK_SIZE,
    CHUNK_OVERLAP,
    ENABLE_TEXT_CLEANING,
    ENABLE_DOCLING,
    MAX_DOCLING_PAGES,
)

from local_ollama_client import OllamaClient

logger = logging.getLogger(__name__)

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å PaddleOCR
try:
    from paddleocr import PaddleOCR

    PADDLEOCR_AVAILABLE = True
except ImportError:
    PADDLEOCR_AVAILABLE = False
    logger.warning("‚ö†Ô∏è PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, OCR –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω.")

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å Docling
try:
    from docling.document_converter import DocumentConverter

    DOCLING_AVAILABLE = True
except ImportError:
    DOCLING_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª Docling –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á—ë–Ω.")


def log_system_stats(stage: str):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
    process = psutil.Process()
    memory = process.memory_info().rss / 1024 / 1024  # MB
    cpu_percent = process.cpu_percent(interval=0.1)

    logger.debug(f"üìä [{stage}] –ü–∞–º—è—Ç—å: {memory:.1f}MB, CPU: {cpu_percent:.1f}%")


def is_trash_text(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞, –≥–æ–¥–∏—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç ‚Äî –º—É—Å–æ—Ä (—Å–ª–∏—à–∫–æ–º –º–∞–ª–æ, –±–∏—Ç–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã).
    """
    if not text:
        return True

    cleaned = text.strip()
    if len(cleaned) < 50:  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 50 —Å–∏–º–≤–æ–ª–æ–≤
        return True

    # –î–æ–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –±—É–∫–≤ vs –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ
    letters = re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë0-9]", cleaned)
    ratio = len(letters) / max(len(cleaned), 1)
    if ratio < 0.2:  # –£–º–µ–Ω—å—à–∏–ª –¥–æ 20%
        # –º–µ–Ω—å—à–µ 20% –±—É–∫–≤/—Ü–∏—Ñ—Ä ‚Äî –ø–æ—Ö–æ–∂–µ –Ω–∞ –º—É—Å–æ—Ä
        return True

    return False


class TextCleaner:
    """–ß–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM (Ollama)"""

    def __init__(self):
        self.enabled = ENABLE_TEXT_CLEANING
        self.ollama = OllamaClient()

    def clean_text(self, text: str, file_name: str = "", page: int = 0) -> str:
        if not self.enabled or not text.strip():
            return text

        system_prompt = (
            "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏.\n\n"
            "–ó–ê–î–ê–ß–ê:\n"
            "- –£–¥–∞–ª–∏ –ø–æ–≤—Ç–æ—Ä—ã —Å—Ç—Ä–æ–∫, –º—É—Å–æ—Ä, –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.\n"
            "- –°–æ—Ö—Ä–∞–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è, –ì–û–°–¢—ã, –Ω–æ–º–µ—Ä–∞ —Å—Ö–µ–º –∏ —Ç.–ø.\n"
            "- –ù–µ —Å–æ–∫—Ä–∞—â–∞–π —Å–º—ã—Å–ª, –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Å–∏–ª—å–Ω–æ.\n"
            "- –ü—Ä–æ—Å—Ç–æ —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–º –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."
        )

        user_prompt = f"–§–∞–π–ª: {file_name}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page}\n\n–¢–µ–∫—Å—Ç:\n{text[:2000]}"  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

        try:
            logger.debug(f"üßπ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ LLM –¥–ª—è —á–∏—Å—Ç–∫–∏ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)...")
            start_time = time.time()
            cleaned = self.ollama.generate(
                prompt=user_prompt,
                system_prompt=system_prompt,
                max_tokens=1024,
            )
            clean_time = time.time() - start_time

            cleaned = cleaned.strip()
            logger.debug(f"‚úÖ LLM –æ—á–∏—Å—Ç–∫–∞: {len(text)} ‚Üí {len(cleaned)} —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ {clean_time:.1f}—Å")

            return cleaned
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM: {repr(e)}")
            return text


class DocumentProcessor:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: PDF, DOCX, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, OCR, Docling, —á–∞–Ω–∫–∏"""

    def __init__(self):
        self.text_cleaner = TextCleaner()

        # OCR
        if ENABLE_OCR and PADDLEOCR_AVAILABLE:
            try:
                self.ocr = PaddleOCR(
                    use_angle_cls=True,
                    lang='ru',
                    use_gpu=False,
                    show_log=False,
                )
                logger.info("‚úÖ PaddleOCR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PaddleOCR: {repr(e)}")
                self.ocr = None
        else:
            self.ocr = None
            if ENABLE_OCR and not PADDLEOCR_AVAILABLE:
                logger.warning("‚ö†Ô∏è ENABLE_OCR=true, –Ω–æ PaddleOCR –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        # Docling
        self.use_docling = ENABLE_DOCLING and DOCLING_AVAILABLE
        if self.use_docling:
            try:
                self.docling_converter = DocumentConverter()
                logger.info("‚úÖ Docling –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º)")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Docling: {repr(e)}")
                self.use_docling = False
                self.docling_converter = None
        else:
            if ENABLE_DOCLING and not DOCLING_AVAILABLE:
                logger.warning("‚ö†Ô∏è ENABLE_DOCLING=true, –Ω–æ Docling –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (pip install docling)")
            self.docling_converter = None

        logger.info("‚úÖ DocumentProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (OCR=%s, Docling=%s)", bool(self.ocr), self.use_docling)

    def process_file(self, file_path: Path) -> List[Dict]:
        ext = file_path.suffix.lower()

        if ext == ".pdf":
            return self._process_pdf(file_path)
        elif ext == ".docx":
            return self._process_docx(file_path)
        else:
            logger.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_path.name}")
            return []

    def _process_pdf(self, file_path: Path) -> List[Dict]:
        """
        –†–æ–±–∞—Å—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF –ø–æ —Å—Ö–µ–º–µ:
        1) pdfplumber (—Ç–µ–∫—Å—Ç + —Ç–∞–±–ª–∏—Ü—ã)
        2) –µ—Å–ª–∏ –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ‚Üí docling
        3) –µ—Å–ª–∏ –∏ docling –Ω–µ –¥–∞–ª ‚Üí OCR –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º —Å—Ç—Ä–∞–Ω–∏—Ü
        4) —á–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ LLM
        5) —á–∞–Ω–∫–∏ ‚Üí –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        """
        fragments = []
        start_time = time.time()

        try:
            logger.info(f"üìÑ –ù–ê–ß–ò–ù–ê–Æ –û–ë–†–ê–ë–û–¢–ö–£ –§–ê–ô–õ–ê: {file_path.name}")

            with pdfplumber.open(file_path) as pdf:
                num_pages = len(pdf.pages)
                logger.info(f"üìä –§–ê–ô–õ {file_path.name}: –≤—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {num_pages}")
                log_system_stats(f"start_{file_path.name}")

                processed_pages = 0
                total_chunks = 0
                successful_pages = 0

                for page_num, page in enumerate(pdf.pages, start=1):
                    processed_pages += 1
                    logger.info(f"   üìÑ –û–ë–†–ê–ë–û–¢–ö–ê –°–¢–†–ê–ù–ò–¶–´ {page_num}/{num_pages} —Ñ–∞–π–ª–∞ {file_path.name}")

                    try:
                        # 1. –ë–ê–ó–û–í–´–ô –¢–ï–ö–°–¢ (pdfplumber)
                        text = page.extract_text() or ""
                        text = text.strip()
                        logger.info(f"      üìù pdfplumber –∏–∑–≤–ª–µ–∫ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")

                        # 2. –¢–ê–ë–õ–ò–¶–´
                        tables_text = ""
                        if ENABLE_TABLES:
                            try:
                                tables = page.extract_tables()
                                if tables:
                                    tables_text = self._format_tables(tables)
                                    logger.info(f"      üìä –ù–∞–π–¥–µ–Ω–æ —Ç–∞–±–ª–∏—Ü: {len(tables)} ({len(tables_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                            except Exception as e:
                                logger.warning(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü: {repr(e)}")

                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç + —Ç–∞–±–ª–∏—Ü—ã
                        combined_text = "\n\n".join(
                            part for part in [text, tables_text] if part and part.strip()).strip()
                        logger.info(f"      üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(combined_text)} —Å–∏–º–≤–æ–ª–æ–≤")

                        # 3. –ü–†–û–í–ï–†–ö–ê: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –º–∞–ª–æ –∏–ª–∏ –º—É—Å–æ—Ä ‚Üí –ø—Ä–æ–±—É–µ–º docling
                        if is_trash_text(combined_text):
                            logger.warning(
                                f"      ‚ö†Ô∏è –ú–ê–õ–û –¢–ï–ö–°–¢–ê –Ω–∞ —Å—Ç—Ä. {page_num} —Ñ–∞–π–ª–∞ {file_path.name} ({len(combined_text)} —Å–∏–º–≤.), –ü–†–û–ë–£–ï–ú DOCLING...")

                            docling_text = self._extract_page_with_docling(file_path, page_num)
                            if docling_text and not is_trash_text(docling_text):
                                logger.info(f"      ‚úÖ DOCLING –£–°–ü–ï–®–ï–ù: {len(docling_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                                combined_text = docling_text
                            else:
                                logger.warning(f"      ‚ö†Ô∏è DOCLING –ù–ï –ü–û–ú–û–ì, –ü–†–û–ë–£–ï–ú OCR...")

                                # 4. OCR –ü–û –ö–ê–†–¢–ò–ù–ö–ï –°–¢–†–ê–ù–ò–¶–´
                                if self.ocr:
                                    try:
                                        ocr_text = self._ocr_page_image(page, file_path.name, page_num)
                                        if ocr_text and not is_trash_text(ocr_text):
                                            logger.info(f"      ‚úÖ OCR –£–°–ü–ï–®–ï–ù: {len(ocr_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                                            combined_text = ocr_text
                                        else:
                                            logger.warning(f"      ‚ùå OCR –¢–û–ñ–ï –ù–ï –î–ê–õ –ù–û–†–ú–ê–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê")
                                    except Exception as e:
                                        logger.error(f"      ‚ùå –û–®–ò–ë–ö–ê OCR: {repr(e)}")
                                else:
                                    logger.warning(f"      ‚ö†Ô∏è OCR –æ—Ç–∫–ª—é—á–µ–Ω")

                        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
                        if not combined_text or is_trash_text(combined_text):
                            logger.warning(
                                f"      ‚ö†Ô∏è –°–¢–†–ê–ù–ò–¶–ê {page_num} –§–ê–ô–õ–ê {file_path.name} –ü–£–°–¢–ê–Ø –ü–û–°–õ–ï –í–°–ï–• –ü–û–ü–´–¢–û–ö, –ü–†–û–ü–£–°–ö–ê–Æ")
                            continue

                        # 5. –ß–ò–°–¢–ö–ê –ß–ï–†–ï–ó LLM
                        if ENABLE_TEXT_CLEANING:
                            logger.info(f"      üßπ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ LLM –¥–ª—è —á–∏—Å—Ç–∫–∏...")
                            cleaned_text = self.text_cleaner.clean_text(
                                combined_text,
                                file_name=file_path.name,
                                page=page_num,
                            )
                            logger.info(f"      ‚úÖ LLM –û–ß–ò–°–¢–ö–ê: {len(combined_text)} ‚Üí {len(cleaned_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        else:
                            cleaned_text = combined_text
                            logger.info(f"      ‚ö†Ô∏è –ß–ò–°–¢–ö–ê LLM –û–¢–ö–õ–Æ–ß–ï–ù–ê, –∏—Å–ø–æ–ª—å–∑—É—é –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")

                        # 6. –ß–ê–ù–ö–ò
                        logger.info(f"      ‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏...")
                        chunks = self._split_into_chunks(cleaned_text)
                        logger.info(f"      ‚úÖ –†–ê–ó–ë–ò–¢–û –ù–ê {len(chunks)} –ß–ê–ù–ö–û–í")
                        total_chunks += len(chunks)

                        for chunk in chunks:
                            fragments.append({
                                "content": chunk,
                                "page": page_num,
                                "type": "text",
                                "file": file_path.name,
                            })

                        successful_pages += 1
                        logger.info(f"      ‚úÖ –°–¢–†–ê–ù–ò–¶–ê {page_num} –£–°–ü–ï–®–ù–û –û–ë–†–ê–ë–û–¢–ê–ù–ê")

                    except Exception as e:
                        logger.error(f"      ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ù–ê –°–¢–†–ê–ù–ò–¶–ï {page_num}: {repr(e)}")
                        continue

                    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    if page_num % 1 == 0:  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                        log_system_stats(f"{file_path.name}_page_{page_num}")

                elapsed = time.time() - start_time
                logger.info(f"üéâ –§–ê–ô–õ {file_path.name} –û–ë–†–ê–ë–û–¢–ê–ù –ó–ê {elapsed:.1f}—Å")
                logger.info(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–õ–Ø {file_path.name}:")
                logger.info(f"   üìÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {successful_pages}/{num_pages}")
                logger.info(f"   üì¶ –í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {total_chunks}")
                logger.info(f"   ‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {elapsed:.1f}—Å")
                if successful_pages > 0:
                    logger.info(f"   üìà –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {elapsed / successful_pages:.1f}—Å")
                    logger.info(f"   üìà –°–∫–æ—Ä–æ—Å—Ç—å: {successful_pages / elapsed:.1f} —Å—Ç—Ä/—Å–µ–∫")
                logger.info(f"   üíæ –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {len(fragments)}")

                return fragments

        except Exception as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –û–ë–†–ê–ë–û–¢–ö–ï PDF {file_path.name}: {repr(e)}")
            return []

    def _extract_page_with_docling(self, file_path: Path, page_num: int) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ Docling.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
        """
        if not self.use_docling or not self.docling_converter:
            return ""

        try:
            logger.info(f"      üß† –ó–∞–ø—É—Å–∫ Docling –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}...")
            result = self.docling_converter.convert(str(file_path))

            for page in result.document.pages:
                if page.page_number == page_num:
                    lines = []
                    for block in page.blocks:
                        txt = block.to_text().strip()
                        if txt:
                            lines.append(txt)

                    if lines:
                        docling_text = "\n".join(lines)
                        logger.info(f"      ‚úÖ Docling –∏–∑–≤–ª–µ–∫ {len(docling_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                        return docling_text

            logger.info(f"      ‚ö†Ô∏è Docling –Ω–µ –Ω–∞—à–µ–ª —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            return ""

        except Exception as e:
            logger.error(f"      ‚ùå –û—à–∏–±–∫–∞ Docling –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num} —Ñ–∞–π–ª–∞ {file_path.name}: {repr(e)}")
            return ""

    def _ocr_page_image(self, page, file_name: str, page_num: int) -> str:
        """OCR —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–µ—Ä–µ–∑ PaddleOCR (–∏–∑ pdfplumber page)"""
        if not self.ocr:
            return ""

        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            logger.info(f"      üñº –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num} –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            img = page.to_image(resolution=200).original  # –£–≤–µ–ª–∏—á–∏–ª —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PIL Image –≤ numpy array
            import numpy as np
            img_np = np.array(img)

            # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB
            if img_np.shape[2] == 4:
                img_np = img_np[:, :, :3]

            logger.info(f"      üî† –ó–∞–ø—É—Å–∫ PaddleOCR –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}...")
            result = self.ocr.ocr(img_np, cls=True)

            if not result or not result[0]:
                logger.info(f"      ‚ö†Ô∏è OCR –Ω–µ –Ω–∞—à—ë–ª —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
                return ""

            lines = []
            for line in result[0]:
                if len(line) > 1:
                    text = line[1][0]
                    if text and text.strip():
                        lines.append(text.strip())

            ocr_text = "\n".join(lines)
            logger.info(f"      ‚úÖ OCR –∏–∑–≤–ª—ë–∫ {len(ocr_text)} —Å–∏–º–≤–æ–ª–æ–≤ —Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")
            return ocr_text

        except Exception as e:
            logger.error(f"      ‚ùå –û—à–∏–±–∫–∞ OCR –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}: {repr(e)}")
            return ""

    def _format_tables(self, tables) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –≤ —Ç–µ–∫—Å—Ç"""
        parts = []
        for table_idx, table in enumerate(tables, 1):
            try:
                for row_idx, row in enumerate(table):
                    row_text = []
                    for cell_idx, cell in enumerate(row):
                        if cell:
                            cell_text = str(cell).strip()
                            row_text.append(cell_text)
                    if row_text:
                        parts.append(" | ".join(row_text))
                parts.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∞–º–∏
            except Exception as e:
                logger.warning(f"      ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã {table_idx}: {repr(e)}")
        return "\n".join(parts)

    def _process_docx(self, file_path: Path) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ DOCX"""
        try:
            from docx import Document
        except ImportError:
            logger.error("‚ùå –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX –Ω—É–∂–µ–Ω –ø–∞–∫–µ—Ç python-docx (pip install python-docx)")
            return []

        fragments = []
        start_time = time.time()

        try:
            logger.info(f"üìÑ –ù–ê–ß–ò–ù–ê–Æ –û–ë–†–ê–ë–û–¢–ö–£ DOCX: {file_path.name}")

            doc = Document(str(file_path))
            full_text = []

            for para in doc.paragraphs:
                txt = (para.text or "").strip()
                if txt:
                    full_text.append(txt)

            combined = "\n".join(full_text).strip()
            if not combined:
                logger.warning(f"‚ö†Ô∏è DOCX {file_path.name} –ø—É—Å—Ç–æ–π")
                return []

            logger.info(f"   üìù –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(combined)} —Å–∏–º–≤–æ–ª–æ–≤")

            if ENABLE_TEXT_CLEANING:
                cleaned_text = self.text_cleaner.clean_text(
                    combined,
                    file_name=file_path.name,
                    page=1,
                )
                logger.info(f"   ‚úÖ LLM –æ—á–∏—Å—Ç–∫–∞: {len(combined)} ‚Üí {len(cleaned_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            else:
                cleaned_text = combined
                logger.info(f"   ‚ö†Ô∏è –ß–ò–°–¢–ö–ê LLM –û–¢–ö–õ–Æ–ß–ï–ù–ê")

            logger.info(f"   ‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏...")
            chunks = self._split_into_chunks(cleaned_text)

            for chunk in chunks:
                fragments.append({
                    "content": chunk,
                    "page": 1,
                    "type": "text",
                    "file": file_path.name,
                })

            elapsed = time.time() - start_time
            logger.info(f"‚úÖ DOCX {file_path.name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∑–∞ {elapsed:.1f}—Å")
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {len(chunks)} —á–∞–Ω–∫–æ–≤")
            logger.info(f"üìà –°–∫–æ—Ä–æ—Å—Ç—å: {len(chunks) / elapsed:.1f} —á–∞–Ω–∫/—Å–µ–∫")

            return fragments

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ DOCX {file_path.name}: {repr(e)}")
            return []

    def _split_into_chunks(self, text: str) -> List[str]:
        """–†–µ–∂–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if not text:
            return []

        chunks = []
        start = 0
        length = len(text)

        logger.info(f"      ‚úÇÔ∏è –ù–∞—á–∏–Ω–∞—é —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏:")
        logger.info(f"         –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {length} —Å–∏–º–≤–æ–ª–æ–≤")
        logger.info(f"         CHUNK_SIZE: {CHUNK_SIZE}")
        logger.info(f"         CHUNK_OVERLAP: {CHUNK_OVERLAP}")

        chunk_num = 1
        while start < length:
            end = min(start + CHUNK_SIZE, length)
            chunk = text[start:end].strip()

            if chunk:
                chunks.append(chunk)
                logger.info(f"         üì¶ –ß–∞–Ω–∫ {chunk_num}: –ø–æ–∑–∏—Ü–∏–∏ {start}-{end} ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤)")
                chunk_num += 1

            start += CHUNK_SIZE - CHUNK_OVERLAP

        logger.info(f"      ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤")

        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        if chunks:
            for i, chunk in enumerate(chunks[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 —á–∞–Ω–∫–∞
                preview = chunk[:100] + "..." if len(chunk) > 100 else chunk
                logger.info(f"         üìÑ –ß–∞–Ω–∫ {i + 1} –ø—Ä–µ–≤—å—é: '{preview}'")

        return chunks