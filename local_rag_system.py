import logging
import json
import time
import psutil
from pathlib import Path
from typing import List, Dict

from tqdm import tqdm

from local_config import (
    DOCUMENTS_FOLDER,
    TOP_K_RESULTS,
    OLLAMA_BASE_URL,
    OLLAMA_MODEL,
    OLLAMA_TEMPERATURE,
)
from local_document_processor import DocumentProcessor
from local_vector_store import VectorStore
from local_ollama_client import OllamaClient

logger = logging.getLogger(__name__)


class RAGSystem:
    """RAG —Å–∏—Å—Ç–µ–º–∞: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è + –ø–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤"""

    def __init__(self):
        self.document_processor = DocumentProcessor()
        self.vector_store = VectorStore()

        # –ñ—ë—Å—Ç–∫–æ –∑–∞–≤—è–∑—ã–≤–∞–µ–º—Å—è –Ω–∞ local_config (local.env)
        self.ollama = OllamaClient(
            base_url=OLLAMA_BASE_URL,
            model=OLLAMA_MODEL,
            temperature=OLLAMA_TEMPERATURE,
        )

        self.indexed_files_path = Path("indexed_files.json")
        self.indexed_files = self._load_indexed_files()

        self._indexing = False
        self._stop_indexing = False

        logger.info("‚úÖ RAGSystem –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _load_indexed_files(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        if self.indexed_files_path.exists():
            try:
                with open(self.indexed_files_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get("indexed_files", [])
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ indexed_files.json: {repr(e)}")
        return []

    def _save_indexed_files(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            with open(self.indexed_files_path, 'w', encoding='utf-8') as f:
                json.dump({"indexed_files": self.indexed_files}, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è indexed_files.json: {repr(e)}")

    def index_documents(self, continue_indexing: bool = True):
        """
        –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ documents/
        """
        if self._indexing:
            logger.warning("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è")
            return

        self._indexing = True
        self._stop_indexing = False

        process_start = time.time()
        process = psutil.Process()

        try:
            if not continue_indexing:
                logger.info("üîÑ –ù–ê–ß–ò–ù–ê–Æ –ü–û–õ–ù–£–Æ –ü–ï–†–ï–ò–ù–î–ï–ö–°–ê–¶–ò–Æ (–æ—á–∏—Å—Ç–∫–∞ –ë–î)...")
                self.vector_store.clear_collection()
                self.indexed_files = []
                logger.info("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –æ—á–∏—â–µ–Ω–∞")

            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
            files = list(DOCUMENTS_FOLDER.glob("*.pdf")) + list(DOCUMENTS_FOLDER.glob("*.docx"))

            if not files:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ {DOCUMENTS_FOLDER}")
                return

            # –§–∏–ª—å—Ç—Ä—É–µ–º —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
            if continue_indexing:
                files_before = len(files)
                files = [f for f in files if f.name not in self.indexed_files]
                files_after = len(files)
                logger.info(f"üìä –§–∞–π–ª–æ–≤ –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {files_before}, –ø–æ—Å–ª–µ: {files_after}")

            if not files:
                logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã")
                return

            logger.info(f"üìö –ù–ê–ô–î–ï–ù–û –§–ê–ô–õ–û–í –î–õ–Ø –ò–ù–î–ï–ö–°–ê–¶–ò–ò: {len(files)}")
            logger.info(f"üìä –ù–∞—á–∏–Ω–∞—é –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é (continue={continue_indexing})")
            logger.info(f"üíæ –ü–∞–º—è—Ç—å –≤ –Ω–∞—á–∞–ª–µ: {process.memory_info().rss / 1024 / 1024:.1f}MB")

            total_fragments = 0
            total_files_processed = 0
            failed_files = []

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
            for file_idx, file_path in enumerate(tqdm(files, desc="–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è", unit="—Ñ–∞–π–ª"), 1):
                if self._stop_indexing:
                    logger.info("üõë –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                    break

                logger.info("\n" + "=" * 80)
                logger.info(f"üìÅ –§–ê–ô–õ {file_idx}/{len(files)}: {file_path.name}")
                logger.info("=" * 80)
                file_start = time.time()

                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
                    logger.info("üìÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞...")
                    fragments = self.document_processor.process_file(file_path)

                    if not fragments:
                        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª {file_path.name} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
                        failed_files.append((file_path.name, "–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞"))
                        continue

                    logger.info(f"üì§ –ó–∞–≥—Ä—É–∑–∫–∞ {len(fragments)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î...")
                    db_start = time.time()
                    self.vector_store.add_documents(fragments)
                    db_time = time.time() - db_start

                    # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π
                    self.indexed_files.append(file_path.name)
                    self._save_indexed_files()

                    total_fragments += len(fragments)
                    total_files_processed += 1

                    file_time = time.time() - file_start
                    memory_usage = process.memory_info().rss / 1024 / 1024

                    logger.info(f"‚úÖ –§–ê–ô–õ {file_path.name} –£–°–ü–ï–®–ù–û –ü–†–û–ò–ù–î–ï–ö–°–ò–†–û–í–ê–ù:")
                    logger.info(f"   üìä –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(fragments)}")
                    logger.info(f"   ‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {file_time:.1f}—Å")
                    logger.info(f"   ‚è±Ô∏è –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î: {db_time:.1f}—Å")
                    logger.info(f"   üíæ –ü–∞–º—è—Ç—å: {memory_usage:.1f}MB")
                    if file_time > 0:
                        logger.info(f"   üìà –°–∫–æ—Ä–æ—Å—Ç—å: {len(fragments) / file_time:.1f} —Ñ—Ä–∞–≥–º/—Å–µ–∫")

                except Exception as e:
                    logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –û–ë–†–ê–ë–û–¢–ö–ï –§–ê–ô–õ–ê {file_path.name}: {repr(e)}")
                    failed_files.append((file_path.name, str(e)))
                    continue

            total_time = time.time() - process_start
            final_memory = process.memory_info().rss / 1024 / 1024

            logger.info("\n" + "=" * 80)
            logger.info("üéâ –ò–ù–î–ï–ö–°–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
            logger.info("=" * 80)
            logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            logger.info(f"   üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {len(files)}")
            logger.info(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_files_processed}")
            logger.info(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {len(failed_files)}")
            logger.info(f"   üìÑ –í—Å–µ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {total_fragments}")
            logger.info(f"   ‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}—Å")
            if total_time > 0:
                logger.info(f"   üìà –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {total_fragments / total_time:.1f} —Ñ—Ä–∞–≥–º/—Å–µ–∫")
            logger.info(f"   üíæ –ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ: {final_memory:.1f}MB")

            if total_files_processed > 0:
                logger.info(f"   üìä –°—Ä–µ–¥–Ω–µ–µ –Ω–∞ —Ñ–∞–π–ª: {total_fragments / total_files_processed:.1f} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

            if failed_files:
                logger.warning("\n‚ö†Ô∏è –ù–ï –£–î–ê–õ–û–°–¨ –û–ë–†–ê–ë–û–¢–ê–¢–¨ –§–ê–ô–õ–´:")
                for file_name, error in failed_files:
                    logger.warning(f"   ‚Ä¢ {file_name}: {error}")

        except Exception as e:
            logger.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –ò–ù–î–ï–ö–°–ê–¶–ò–ò: {repr(e)}")
            raise

        finally:
            self._indexing = False
            self._stop_indexing = False

    def is_indexing(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞: –∏–¥—ë—Ç –ª–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è"""
        return self._indexing

    def stop_indexing_process(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        self._stop_indexing = True

    def query(self, user_query: str, top_k: int = TOP_K_RESULTS) -> Dict:
        """
        –ü–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞

        Returns:
            {"answer": "–æ—Ç–≤–µ—Ç", "sources": [...], "relevance": float}
        """
        logger.info(f"üí¨ –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_query}")

        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        logger.info("üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        documents = self.vector_store.search(user_query, top_k=top_k)

        if not documents:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {user_query}")
            return {
                "answer": "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.",
                "sources": [],
                "relevance": 0.0,
            }

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        avg_score = sum(doc.get('score', 0) for doc in documents) / len(documents)
        relevance_percent = avg_score * 100

        # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context_parts = []
        for idx, doc in enumerate(documents, start=1):
            context_parts.append(
                f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {idx}: {doc['file']}, —Å—Ç—Ä. {doc['page']}]\n{doc['content']}"
            )

        context = "\n\n---\n\n".join(context_parts)

        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ LLM
        system_prompt = """–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π –ø–æ –ª–∏—Ñ—Ç–∞–º –∏ –ª–∏—Ñ—Ç–æ–≤–æ–º—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é.

–¢–í–û–ò –ñ–Å–°–¢–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
- –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
- –ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏–ª–∏ —Å–≤–æ–∏ –¥–æ–≥–∞–¥–∫–∏.
- –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ù–ï–¢ ‚Äî –ø—Ä—è–º–æ —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏:
  "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
- –ù–ï –ø–æ–¥–º–µ–Ω—è–π –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ/–ø–ª–∞—Ç—É –¥—Ä—É–≥–∏–º.
- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
- –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–±–ª–∏—Ü–∞ –∏–ª–∏ —è–≤–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è ‚Äî –ø—Ä–∏–≤–µ–¥–∏ –∏—Ö —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô –∏ –ù–ï –î–û–ì–ê–î–´–í–ê–ô–°–Ø.
- –õ—É—á—à–µ —á–µ—Å—Ç–Ω–æ –æ—Ç–≤–µ—Ç—å "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ <—Ç–µ—Ä–º–∏–Ω> –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ö –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞", —á–µ–º –Ω–∞–ø–∏—Å–∞—Ç—å —á—É—à—å."""

        prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:

{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{user_query}

–û—Ç–≤–µ—Ç:"""

        logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
        answer = self.ollama.generate(prompt, system_prompt=system_prompt)

        # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        sources = [
            {
                "file": doc["file"],
                "page": doc["page"],
                "score": round(doc["score"], 3),
            }
            for doc in documents
        ]

        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_percent:.1f}%")

        return {
            "answer": answer,
            "sources": sources,
            "relevance": relevance_percent,
        }

    def query_with_history(self, history: List[Dict], user_query: str, top_k: int = TOP_K_RESULTS) -> Dict:
        """
        –ü–æ–∏—Å–∫ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
        """
        logger.info(f"üí¨ –ó–ê–ü–†–û–° –° –ò–°–¢–û–†–ò–ï–ô: {user_query}")
        logger.info(f"üìä –†–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏: {len(history)} —Å–æ–æ–±—â–µ–Ω–∏–π")

        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        logger.info("üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        documents = self.vector_store.search(user_query, top_k=top_k)

        if not documents:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {user_query}")
            return {
                "answer": "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã.",
                "sources": [],
                "relevance": 0.0,
            }

        avg_score = sum(doc.get('score', 0) for doc in documents) / len(documents)
        relevance_percent = avg_score * 100

        # 2. –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        context_parts = []
        for idx, doc in enumerate(documents, start=1):
            context_parts.append(
                f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {idx}: {doc['file']}, —Å—Ç—Ä. {doc['page']}]\n{doc['content']}"
            )
        context = "\n\n---\n\n".join(context_parts)

        # 3. –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
        history_text = ""
        if history:
            history_lines = []
            for msg in history[-10:]:
                role = msg.get("role", "user")
                content = (msg.get("content") or "").strip()
                if not content:
                    continue
                prefix = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:" if role == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç:"
                history_lines.append(f"{prefix} {content}")

            if history_lines:
                history_text = "\n".join(history_lines)
                logger.info(f"üìú –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏—Å—Ç–æ—Ä–∏—è –∏–∑ {len(history_lines)} —Å–æ–æ–±—â–µ–Ω–∏–π")

        system_prompt = """–¢—ã ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π –ø–æ –ª–∏—Ñ—Ç–∞–º –∏ –ª–∏—Ñ—Ç–æ–≤–æ–º—É –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é.

–¢–í–û–ò –ñ–Å–°–¢–ö–ò–ï –ü–†–ê–í–ò–õ–ê:
- –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
- –ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –∏–ª–∏ —Å–≤–æ–∏ –¥–æ–≥–∞–¥–∫–∏.
- –ï—Å–ª–∏ —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ù–ï–¢ ‚Äî –ø—Ä—è–º–æ —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏:
  "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
- –ù–ï –ø–æ–¥–º–µ–Ω—è–π –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ/–ø–ª–∞—Ç—É –¥—Ä—É–≥–∏–º.
- –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
- –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–±–ª–∏—Ü–∞ –∏–ª–∏ —è–≤–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è ‚Äî –ø—Ä–∏–≤–µ–¥–∏ –∏—Ö —Å–ª–æ–≤–∞–º–∏ –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ù–ï –ü–†–ò–î–£–ú–´–í–ê–ô –∏ –ù–ï –î–û–ì–ê–î–´–í–ê–ô–°–Ø."""

        prompt_parts = []

        if history_text:
            prompt_parts.append(f"–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n{history_text}\n")

        prompt_parts.append(f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:\n{context}\n")
        prompt_parts.append(f"–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{user_query}\n")
        prompt_parts.append("–û—Ç–≤–µ—Ç:")

        prompt = "\n".join(prompt_parts)

        logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏...")
        answer = self.ollama.generate(prompt, system_prompt=system_prompt)

        sources = [
            {
                "file": doc["file"],
                "page": doc["page"],
                "score": round(doc["score"], 3),
            }
            for doc in documents
        ]

        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_percent:.1f}%")

        return {
            "answer": answer,
            "sources": sources,
            "relevance": relevance_percent,
        }

    def generate_clarification_questions(self, user_query: str) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤"""
        system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏.
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å.
–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ—Ä–æ—Ç–∫–∏–µ —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã (–∫–∞–∂–¥—ã–π –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ).
–í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –û–ß–ï–ù–¨ –∫–æ—Ä–æ—Ç–∫–∏–º–∏ (–º–∞–∫—Å–∏–º—É–º 5-7 —Å–ª–æ–≤).
–ì–µ–Ω–µ—Ä–∏—Ä—É–π —Å—Ç–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤, —Å–∫–æ–ª—å–∫–æ —Å—á–∏—Ç–∞–µ—à—å –Ω—É–∂–Ω—ã–º –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è."""

        prompt = f"""–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_query}

–£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:"""

        try:
            logger.info(f"‚ùì –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è: {user_query}")
            response = self.ollama.generate(prompt, system_prompt=system_prompt)

            questions = [q.strip() for q in response.split('\n') if q.strip()]
            questions = [q.lstrip('0123456789.-) ') for q in questions]
            questions = [q for q in questions if q and len(q.split()) <= 10]

            logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(questions)} —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")
            return questions

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤: {repr(e)}")
            return []

    def get_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã"""
        vector_stats = self.vector_store.get_stats()

        return {
            "indexed_files_count": len(self.indexed_files),
            "indexed_files_list": self.indexed_files,
            "total_documents": vector_stats.get("total_documents", 0),
            "vector_size": vector_stats.get("vector_size", 0),
            "embedding_model": vector_stats.get("model", "unknown"),
        }

    def test_connection(self) -> Dict[str, str]:
        """–¢–µ—Å—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        results = []

        # 1. –¢–µ—Å—Ç Ollama
        try:
            ok = self.ollama.test_connection()
            if ok:
                results.append(f"‚úÖ Ollama: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ, –º–æ–¥–µ–ª—å {self.ollama.model} –¥–æ—Å—Ç—É–ø–Ω–∞.")
            else:
                results.append(f"‚ùå Ollama: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ {self.ollama.model}.")
        except Exception as e:
            results.append(f"‚ùå Ollama: –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {repr(e)}")

        # 2. –¢–µ—Å—Ç Qdrant
        try:
            qdrant_test = self.vector_store.test_connection()
            if isinstance(qdrant_test, dict) and "message" in qdrant_test:
                results.append(qdrant_test["message"])
            else:
                results.append(f"‚ÑπÔ∏è Qdrant: {qdrant_test}")
        except Exception as e:
            results.append(f"‚ùå Qdrant: –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {repr(e)}")

        return {"message": "\n\n".join(results)}